use std::collections::HashSet;

use schemars::{
    generate::{SchemaGenerator, SchemaSettings},
    JsonSchema,
};
use serde_json::{json, Map, Value};
use sha2::{Digest, Sha256};
use tracing::debug;

use crate::error::{Result, StructuredError};

/// Trait implemented by any type that can be used as a structured Gemini response.
pub trait GeminiStructured: JsonSchema {
    /// Produce a Gemini-compatible OpenAPI 3 schema.
    fn gemini_schema() -> Value {
        let settings = SchemaSettings::openapi3().with(|s| {
            // Inline subschemas to keep strict-mode compatibility.
            s.inline_subschemas = true;
            s.meta_schema = None;
        });

        let generator = SchemaGenerator::new(settings);
        let schema = generator.into_root_schema_for::<Self>();
        let mut value = serde_json::to_value(&schema).unwrap();

        clean_schema_for_gemini(&mut value);
        value
    }

    /// Stable hash for caching schemas and prompts.
    fn gemini_schema_hash() -> String {
        schema_hash(&Self::gemini_schema())
    }
}

impl<T: JsonSchema> GeminiStructured for T {}

/// Compile a JSON Schema validator for the given type.
pub fn compile_validator<T: GeminiStructured>() -> Result<jsonschema::Validator> {
    let schema = T::gemini_schema();
    let validation_schema = to_standard_json_schema(schema);
    jsonschema::validator_for(&validation_schema)
        .map_err(|e| StructuredError::Validation(format!("Failed to compile schema: {e}")))
}

/// Compute a stable hash for a schema or prompt fragment.
pub fn schema_hash(value: &Value) -> String {
    let mut hasher = Sha256::new();
    hasher.update(value.to_string());
    let digest = hasher.finalize();
    digest
        .iter()
        .map(|b| format!("{:02x}", b))
        .collect::<String>()
}

/// Optional logical validator that types can implement to enforce domain rules
/// that JSON Schema cannot express.
///
/// All types get a default implementation that always returns `None` (valid).
/// To add custom validation, manually implement this trait for your type.
pub trait StructuredValidator {
    /// Return `Some(message)` when invalid, otherwise `None`.
    fn validate(&self) -> Option<String>;
}

/// Blanket implementation providing default "always valid" behavior for all types.
impl<T> StructuredValidator for T {
    fn validate(&self) -> Option<String> {
        None
    }
}

/// Trait for custom validation logic generated by `#[derive(GeminiValidated)]`.
///
/// This trait is separate from `StructuredValidator` to allow the derive macro
/// to work alongside the blanket implementation of `StructuredValidator`.
///
/// Types implementing this trait should also implement `StructuredValidator`
/// manually to integrate with the library's validation flow.
pub trait GeminiValidator {
    /// Perform custom validation. Returns `Some(error_message)` if invalid.
    fn gemini_validate(&self) -> Option<String>;
}

/// Recursively strip or normalize fields that Gemini strict schema mode does not support.
pub fn clean_schema_for_gemini(value: &mut Value) {
    debug!(
        schema_before = %serde_json::to_string_pretty(value).unwrap_or_default(),
        "Schema before cleaning"
    );

    let snapshot = value.clone();
    let mut stack = Vec::new();
    inline_refs(value, &snapshot, &mut stack);
    clean_schema_node(value);

    debug!(
        schema_after = %serde_json::to_string_pretty(value).unwrap_or_default(),
        "Schema after cleaning"
    );
}

fn inline_refs(value: &mut Value, root: &Value, stack: &mut Vec<String>) {
    match value {
        Value::Object(map) => {
            if let Some(Value::String(reference)) = map.get("$ref") {
                let reference = reference.clone();
                if stack.contains(&reference) {
                    *value = Value::Object(Map::new());
                    return;
                }
                if let Some(resolved) = resolve_pointer(root, &reference) {
                    stack.push(reference);
                    let mut resolved = resolved.clone();
                    inline_refs(&mut resolved, root, stack);
                    stack.pop();
                    *value = resolved;
                    return;
                }
                *value = Value::Object(Map::new());
                return;
            }

            for (_, v) in map.iter_mut() {
                inline_refs(v, root, stack);
            }
        }
        Value::Array(arr) => {
            for v in arr {
                inline_refs(v, root, stack);
            }
        }
        _ => {}
    }
}

fn resolve_pointer<'a>(root: &'a Value, reference: &str) -> Option<&'a Value> {
    let pointer = reference.strip_prefix('#').unwrap_or(reference);
    root.pointer(pointer)
}

/// Determines the JSON Schema type from the schema node.
fn get_schema_type(map: &Map<String, Value>) -> Option<&str> {
    map.get("type").and_then(|v| v.as_str())
}

/// Common tag field names used for internally-tagged enums
const TAG_FIELD_NAMES: &[&str] = &["type", "kind", "model", "variant", "tag"];

/// Merges enum values from a new variant into an existing tag field
fn merge_tag_field(existing: &mut Value, new_variant: &Value) {
    // Extract enum values from both existing and new
    let existing_enums = existing
        .as_object()
        .and_then(|obj| obj.get("enum"))
        .and_then(|e| e.as_array())
        .cloned()
        .unwrap_or_default();

    let new_enums = new_variant
        .as_object()
        .and_then(|obj| obj.get("enum"))
        .and_then(|e| e.as_array())
        .cloned()
        .unwrap_or_default();

    // Merge enum values, avoiding duplicates
    let mut merged: Vec<Value> = existing_enums;
    for val in new_enums {
        if !merged.contains(&val) {
            merged.push(val);
        }
    }

    // Update the existing field with merged enum
    if let Some(obj) = existing.as_object_mut() {
        if !merged.is_empty() {
            obj.insert("enum".to_string(), json!(merged));
        }
        // Merge descriptions if both have them
        if let (Some(existing_desc), Some(new_desc)) = (
            obj.get("description").and_then(|d| d.as_str()),
            new_variant
                .as_object()
                .and_then(|o| o.get("description"))
                .and_then(|d| d.as_str()),
        ) {
            if existing_desc != new_desc && !existing_desc.contains(new_desc) {
                obj.insert(
                    "description".to_string(),
                    json!(format!("{} | {}", existing_desc, new_desc)),
                );
            }
        }
    }
}

/// Merges multiple schema variants into a single permissive object schema.
/// This allows Gemini to understand enum types by flattening all variant properties
/// into a single schema with the tag field containing all possible values.
fn flatten_variants(parent: &mut Map<String, Value>, variants: Vec<Value>) {
    // Force type to object
    parent.insert("type".to_string(), json!("object"));

    // Initialize or get the properties map
    let parent_props = parent
        .entry("properties".to_string())
        .or_insert(json!({}))
        .as_object_mut();

    let Some(parent_props) = parent_props else {
        return;
    };

    // Track required fields across variants for intersection
    let mut common_required: Option<HashSet<String>> = None;

    // Collect all descriptions from variants for the parent
    let mut variant_descriptions: Vec<String> = Vec::new();

    for variant in variants {
        if let Value::Object(v_map) = variant {
            // Collect variant description
            if let Some(desc) = v_map.get("description").and_then(|d| d.as_str()) {
                variant_descriptions.push(desc.to_string());
            }

            // Merge properties from this variant
            if let Some(Value::Object(props)) = v_map.get("properties") {
                for (k, v) in props {
                    if !parent_props.contains_key(k) {
                        parent_props.insert(k.clone(), v.clone());
                    } else if TAG_FIELD_NAMES.contains(&k.as_str()) {
                        // Merge enum values for tag fields
                        merge_tag_field(parent_props.get_mut(k).unwrap(), v);
                    }
                }
            }

            // Intersect required fields (only keep fields required in ALL variants)
            if let Some(Value::Array(req_arr)) = v_map.get("required") {
                let variant_required: HashSet<String> = req_arr
                    .iter()
                    .filter_map(|v| v.as_str().map(String::from))
                    .collect();

                common_required = Some(match common_required.take() {
                    Some(existing) => existing.intersection(&variant_required).cloned().collect(),
                    None => variant_required,
                });
            }
        }
    }

    // Set the intersected required fields
    if let Some(required) = common_required {
        if !required.is_empty() {
            let required_vec: Vec<Value> = required.into_iter().map(Value::String).collect();
            parent.insert("required".to_string(), json!(required_vec));
        }
    }

    // Add combined description if we collected any
    if !variant_descriptions.is_empty() && !parent.contains_key("description") {
        parent.insert(
            "description".to_string(),
            json!(format!(
                "One of the following variants: {}",
                variant_descriptions.join(" | ")
            )),
        );
    }

    // Note: We don't need to clean properties here because variants are pre-cleaned
    // before being passed to flatten_variants.
}

/// Clean a schema node based on Gemini's supported properties per type.
///
/// Gemini supports the following JSON Schema properties:
/// - Common: type, title, description, nullable, enum
/// - For objects: properties, required, additionalProperties
/// - For strings: enum, format
/// - For numbers/integers: enum, minimum, maximum
/// - For arrays: items, prefixItems, minItems, maxItems
///
/// This function uses an iterative approach with an explicit stack to avoid
/// call stack overflow when processing deeply nested schemas (e.g., recursive types).
fn clean_schema_node(root: &mut Value) {
    // Iterative cleaning using explicit stack.
    // We may need multiple passes because:
    // 1. oneOf/anyOf variants may have allOf that needs merging first
    // 2. After allOf is merged, we can properly detect variant types
    const MAX_PASSES: usize = 100;

    for _ in 0..MAX_PASSES {
        let mut changed = false;
        let mut stack: Vec<*mut Value> = vec![root as *mut Value];

        while let Some(ptr) = stack.pop() {
            // SAFETY: These pointers come from our owned data structure.
            // We never create aliasing mutable references - each node is
            // visited exactly once per pass.
            let value = unsafe { &mut *ptr };

            if let Value::Object(map) = value {
                changed |= clean_object_node(map);

                // Queue all children for processing (including anyOf/oneOf variants)
                for v in map.values_mut() {
                    stack.push(v as *mut Value);
                }
            } else if let Value::Array(arr) = value {
                for v in arr.iter_mut() {
                    stack.push(v as *mut Value);
                }
            }
        }

        if !changed {
            break;
        }
    }
}

/// Process a single object node. Returns true if any changes were made.
fn clean_object_node(map: &mut Map<String, Value>) -> bool {
    let mut changed = false;

    // Handle allOf by merging sub-schemas into the parent.
    // This is crucial for handling schemars' pattern of using allOf to attach descriptions to refs.
    if let Some(Value::Array(all_of)) = map.remove("allOf") {
        changed = true;
        for sub_schema in all_of {
            if let Value::Object(sub_map) = sub_schema {
                for (k, v) in sub_map {
                    match k.as_str() {
                        "properties" => {
                            // Merge properties: add child properties to parent
                            let parent_props = map
                                .entry("properties")
                                .or_insert(json!({}))
                                .as_object_mut()
                                .unwrap();
                            if let Value::Object(child_props) = v {
                                for (pk, pv) in child_props {
                                    parent_props.insert(pk, pv);
                                }
                            }
                        }
                        "required" => {
                            // Merge required arrays, avoiding duplicates
                            if let Value::Array(child_req) = v {
                                let parent_req = map
                                    .entry("required")
                                    .or_insert(json!([]))
                                    .as_array_mut()
                                    .unwrap();
                                for r in child_req {
                                    if !parent_req.contains(&r) {
                                        parent_req.push(r);
                                    }
                                }
                            }
                        }
                        // For other keys (type, enum, items, etc.), adopt them if missing in parent
                        _ => {
                            if !map.contains_key(&k) {
                                map.insert(k, v);
                            }
                        }
                    }
                }
            }
        }
    }

    // Normalize array types to single types with nullable flag.
    // Gemini API requires type: "string", not type: ["string", "null"].
    if let Some(Value::Array(types)) = map.get("type").cloned() {
        let type_strs: Vec<String> = types
            .iter()
            .filter_map(|v| v.as_str().map(String::from))
            .collect();

        let has_null = type_strs.iter().any(|t| t == "null");
        let real_types: Vec<String> = type_strs.into_iter().filter(|t| t != "null").collect();

        if real_types.len() == 1 {
            changed = true;
            map.insert("type".to_string(), json!(real_types[0]));
            if has_null {
                map.insert("nullable".to_string(), json!(true));
            }
        } else if real_types.is_empty() && has_null {
            changed = true;
            map.remove("type");
            map.insert("nullable".to_string(), json!(true));
        } else if !real_types.is_empty() {
            changed = true;
            let variants: Vec<Value> = real_types
                .into_iter()
                .map(|t| json!({ "type": t }))
                .collect();
            map.remove("type");
            map.insert("anyOf".to_string(), Value::Array(variants));
            if has_null {
                map.insert("nullable".to_string(), json!(true));
            }
        }
    }

    // Properties that are never supported by Gemini
    let always_unsupported = [
        "$schema",
        "$ref",
        "components",
        "definitions",
        "$defs",
        "default",
        "examples",
        "not",
        "if",
        "then",
        "else",
    ];

    for key in always_unsupported {
        if map.remove(key).is_some() {
            changed = true;
        }
    }

    // Handle oneOf/anyOf intelligently based on variant types
    if let Some(Value::Array(variants)) = map.remove("oneOf").or_else(|| map.remove("anyOf")) {
        changed = true;

        // Check if any variant still has allOf (needs another pass to process)
        let variants_need_processing = variants
            .iter()
            .any(|v| v.get("allOf").is_some());

        if variants_need_processing {
            // Put it back as anyOf - it will be processed in the next pass
            // after the variants' allOf are merged
            map.insert("anyOf".to_string(), Value::Array(variants));
        } else {
            // Check if this is a simple string enum
            let is_pure_string_enum = variants.iter().all(|v| {
                let is_string = v.get("type").and_then(|t| t.as_str()) == Some("string");
                let has_const_string = v.get("const").and_then(|c| c.as_str()).is_some();
                let has_enum = v.get("enum").is_some();
                (is_string || has_const_string || has_enum)
                    && (v.get("const").is_some() || has_enum)
            });

            if is_pure_string_enum {
                // CASE 1: Pure String Enum - convert to { "type": "string", "enum": [...] }
                let mut enum_values = Vec::new();
                for v in &variants {
                    if let Some(c) = v.get("const") {
                        enum_values.push(c.clone());
                    } else if let Some(Value::Array(enums)) = v.get("enum") {
                        enum_values.extend(enums.clone());
                    }
                }
                enum_values.sort_by_key(|a| a.to_string());
                enum_values.dedup();

                map.insert("type".to_string(), json!("string"));
                map.insert("enum".to_string(), Value::Array(enum_values));
            } else {
                // Check for mixed types (Strings AND Objects)
                let has_objects = variants.iter().any(|v| {
                    v.get("type").and_then(|t| t.as_str()) == Some("object")
                        || v.get("properties").is_some()
                });
                let has_strings = variants.iter().any(|v| {
                    v.get("type").and_then(|t| t.as_str()) == Some("string")
                        || v.get("enum").is_some()
                });

                if has_objects && has_strings {
                    // CASE 2: Mixed Enum - preserve as anyOf
                    map.insert("anyOf".to_string(), Value::Array(variants));
                    map.remove("type");
                    map.remove("properties");
                    map.remove("required");
                    map.remove("enum");
                } else {
                    // CASE 3: Complex Object Union - flatten
                    flatten_variants(map, variants);
                }
            }
        }
    }

    // Remove const at the top level
    if map.remove("const").is_some() {
        changed = true;
    }

    // Get the type to determine which properties to keep
    let schema_type = get_schema_type(map).map(|s| s.to_string());

    // Properties only valid for specific types
    match schema_type.as_deref() {
        Some("object") => {
            map.remove("pattern");
            map.remove("minLength");
            map.remove("maxLength");
            map.remove("format");
            map.remove("items");
            map.remove("prefixItems");
            map.remove("minItems");
            map.remove("maxItems");
            map.remove("minimum");
            map.remove("maximum");
            map.remove("minProperties");
            map.remove("maxProperties");
        }
        Some("array") => {
            map.remove("properties");
            map.remove("required");
            map.remove("additionalProperties");
            map.remove("pattern");
            map.remove("minLength");
            map.remove("maxLength");
            map.remove("format");
            map.remove("minimum");
            map.remove("maximum");
            map.remove("minProperties");
            map.remove("maxProperties");
        }
        Some("string") => {
            map.remove("properties");
            map.remove("required");
            map.remove("additionalProperties");
            map.remove("items");
            map.remove("prefixItems");
            map.remove("minItems");
            map.remove("maxItems");
            map.remove("minimum");
            map.remove("maximum");
            map.remove("pattern");
            map.remove("minLength");
            map.remove("maxLength");
            map.remove("minProperties");
            map.remove("maxProperties");
        }
        Some("number") | Some("integer") => {
            map.remove("properties");
            map.remove("required");
            map.remove("additionalProperties");
            map.remove("items");
            map.remove("prefixItems");
            map.remove("minItems");
            map.remove("maxItems");
            map.remove("pattern");
            map.remove("minLength");
            map.remove("maxLength");
            map.remove("format");
            map.remove("minProperties");
            map.remove("maxProperties");
        }
        Some("boolean") | Some("null") => {
            map.remove("properties");
            map.remove("required");
            map.remove("additionalProperties");
            map.remove("items");
            map.remove("prefixItems");
            map.remove("minItems");
            map.remove("maxItems");
            map.remove("pattern");
            map.remove("minLength");
            map.remove("maxLength");
            map.remove("format");
            map.remove("minimum");
            map.remove("maximum");
            map.remove("minProperties");
            map.remove("maxProperties");
        }
        _ => {
            map.remove("additionalProperties");
            map.remove("pattern");
            map.remove("minLength");
            map.remove("maxLength");
            map.remove("minProperties");
            map.remove("maxProperties");
        }
    }

    // SPECIAL HANDLING FOR HASHMAPS (additionalProperties)
    if let Some(add_props) = map.remove("additionalProperties") {
        changed = true;
        let has_specific_props = map
            .get("properties")
            .and_then(|p| p.as_object())
            .is_some_and(|o| !o.is_empty());

        if !has_specific_props && add_props.is_object() {
            map.insert("type".to_string(), json!("array"));
            map.insert(
                "items".to_string(),
                json!({
                    "type": "object",
                    "properties": {
                        "__key__": { "type": "string" },
                        "__value__": add_props
                    },
                    "required": ["__key__", "__value__"]
                }),
            );
            map.remove("required");
            map.remove("properties");
        }
    }

    // GENERAL CLEANUP FOR EMPTY OBJECTS
    if get_schema_type(map) == Some("object") {
        let has_properties = map
            .get("properties")
            .and_then(|p| p.as_object())
            .is_some_and(|p| !p.is_empty());

        if !has_properties {
            changed = true;
            map.remove("type");
            map.remove("required");
            map.remove("properties");
            map.remove("additionalProperties");
        }
    }

    changed
}

/// Recursively normalizes the JSON response from Gemini.
/// Converts Arrays of {__key__, __value__} back into Objects { key: value }.
pub fn normalize_json_response(value: &mut Value) {
    match value {
        Value::Array(arr) => {
            // Check if this array looks like a transformed Map
            let is_kv_map = !arr.is_empty()
                && arr.iter().all(|item| {
                    item.as_object()
                        .is_some_and(|o| o.contains_key("__key__") && o.contains_key("__value__"))
                });

            if is_kv_map {
                let mut map = Map::new();
                for item in arr.drain(..) {
                    if let Value::Object(mut obj) = item {
                        if let (Some(Value::String(key)), Some(mut val)) =
                            (obj.remove("__key__"), obj.remove("__value__"))
                        {
                            // Recurse into value before inserting
                            normalize_json_response(&mut val);
                            map.insert(key, val);
                        }
                    }
                }
                *value = Value::Object(map);
            } else {
                // Normal array, recurse
                for item in arr {
                    normalize_json_response(item);
                }
            }
        }
        Value::Object(map) => {
            for v in map.values_mut() {
                normalize_json_response(v);
            }
        }
        _ => {}
    }
}

/// Helper to check if a schema node requires a specific string value.
/// Used to match collapsed string values against schema constraints.
fn schema_matches_const_string(schema: &Value, target: &str) -> bool {
    // Case 1: "const": "mstl"
    if let Some(c) = schema.get("const").and_then(|v| v.as_str()) {
        return c == target;
    }

    // Case 2: "enum": ["mstl"]
    if let Some(enums) = schema.get("enum").and_then(|v| v.as_array()) {
        // Only match if it's a specific signifier, usually arrays of size 1 for tags
        if enums.len() == 1 {
            if let Some(e_str) = enums[0].as_str() {
                return e_str == target;
            }
        }
    }

    false
}

/// Recursively attempts to recover internally tagged enums where the LLM
/// output a string literal instead of the wrapper object.
///
/// Example: matches "mstl" against a schema expecting { "type": "mstl" }
/// and rewrites the JSON value to match the schema.
///
/// This handles Gemini's tendency (especially with Flash models) to collapse
/// objects with single discriminator fields into just the string value.
pub fn recover_internally_tagged_enums(value: &mut Value, schema: &Value) {
    match value {
        Value::Array(arr) => {
            // Handle arrays: check if schema defines items
            if let Some(items_schema) = schema.get("items") {
                for item in arr {
                    recover_internally_tagged_enums(item, items_schema);
                }
            } else if let Some(prefix_items) = schema.get("prefixItems").and_then(|v| v.as_array())
            {
                // Handle tuple structs / prefixItems
                for (i, item) in arr.iter_mut().enumerate() {
                    if let Some(sub_schema) = prefix_items.get(i) {
                        recover_internally_tagged_enums(item, sub_schema);
                    }
                }
            }
        }
        Value::Object(map) => {
            // Handle objects: recurse into properties
            if let Some(props) = schema.get("properties").and_then(|v| v.as_object()) {
                for (k, v) in map {
                    if let Some(sub_schema) = props.get(k) {
                        recover_internally_tagged_enums(v, sub_schema);
                    }
                }
            }
        }
        Value::String(s) => {
            // THE FIX: Check if this string should actually be an object
            // This happens when serde(tag=...) is used and the LLM optimizes away the wrapper.

            // Check if we are inside a oneOf/anyOf
            let variants = schema
                .get("oneOf")
                .or_else(|| schema.get("anyOf"))
                .and_then(|v| v.as_array());

            if let Some(variants) = variants {
                for variant in variants {
                    // We are looking for a variant that is an OBJECT containing a property
                    // that matches our string exactly.
                    if let Some(props) = variant.get("properties").and_then(|p| p.as_object()) {
                        for (prop_name, prop_schema) in props {
                            // Does this property match our string?
                            if schema_matches_const_string(prop_schema, s) {
                                // Found it! Transform "val" -> { "tag": "val" }
                                debug!(
                                    "Recovering internally tagged enum: expanded string '{}' to object with tag '{}'",
                                    s, prop_name
                                );
                                *value = json!({ prop_name: s });
                                return;
                            }
                        }
                    }
                }
            }

            // Also check the root properties case (less common for enums but possible)
            if let Some(props) = schema.get("properties").and_then(|p| p.as_object()) {
                for (prop_name, prop_schema) in props {
                    if schema_matches_const_string(prop_schema, s) {
                        // Check if this property is REQUIRED. If so, and we only have a string,
                        // the LLM likely collapsed the object to this single identifying property.
                        if let Some(req) = schema.get("required").and_then(|r| r.as_array()) {
                            if req.contains(&json!(prop_name)) {
                                *value = json!({ prop_name: s });
                                return;
                            }
                        }
                    }
                }
            }
        }
        _ => {}
    }
}

/// Convert an OpenAPI-style schema (with nullable: true) to a standard JSON Schema
/// (with type: [T, "null"]) for compatibility with the jsonschema crate.
fn to_standard_json_schema(mut schema: Value) -> Value {
    if let Value::Object(ref mut map) = schema {
        // Handle nullable: true
        if let Some(Value::Bool(true)) = map.remove("nullable") {
            if let Some(type_val) = map.get_mut("type") {
                match type_val {
                    Value::String(s) => {
                        *type_val = serde_json::json!([s, "null"]);
                    }
                    Value::Array(arr) => {
                        let has_null = arr.iter().any(|v| v.as_str() == Some("null"));
                        if !has_null {
                            arr.push(Value::String("null".to_string()));
                        }
                    }
                    _ => {}
                }
            }
        }

        for val in map.values_mut() {
            let taken = std::mem::replace(val, Value::Null);
            *val = to_standard_json_schema(taken);
        }
    } else if let Value::Array(arr) = schema {
        let new_arr = arr.into_iter().map(to_standard_json_schema).collect();
        return Value::Array(new_arr);
    }
    schema
}

#[cfg(test)]
mod tests {
    use super::*;
    use schemars::JsonSchema;
    use serde_json::json;
    use std::collections::HashMap;

    #[derive(JsonSchema)]
    struct Contact {
        phone: Option<String>,
    }

    #[test]
    fn option_fields_keep_nullable_flag() {
        let contact = Contact {
            phone: Some("123".to_string()),
        };
        // Read the field to avoid dead-code warnings while keeping the shape realistic.
        assert_eq!(contact.phone.as_deref(), Some("123"));

        let schema = Contact::gemini_schema();
        let phone_schema = schema
            .get("properties")
            .and_then(|p| p.get("phone"))
            .expect("phone schema should exist");

        assert_eq!(phone_schema.get("type"), Some(&json!("string")));
        assert_eq!(phone_schema.get("nullable"), Some(&json!(true)));
    }

    #[test]
    fn to_standard_json_schema_handles_nullable() {
        let openapi_schema = json!({
            "type": "string",
            "nullable": true
        });

        let standard = to_standard_json_schema(openapi_schema);
        assert_eq!(standard.get("nullable"), None);
        let types = standard
            .get("type")
            .and_then(|t| t.as_array())
            .expect("type should be array");
        assert!(types.contains(&json!("string")));
        assert!(types.contains(&json!("null")));
    }

    #[derive(JsonSchema)]
    struct MapWrapper {
        map: HashMap<String, String>,
    }

    #[test]
    fn map_schemas_transform_to_array() {
        let schema = MapWrapper::gemini_schema();
        let map_schema = schema
            .get("properties")
            .and_then(|p| p.get("map"))
            .expect("map schema should exist");

        // HashMap schemas are transformed to arrays with __key__/__value__ items
        assert_eq!(map_schema.get("type"), Some(&json!("array")));
        assert!(map_schema.get("additionalProperties").is_none());

        // Check the items schema
        let items_schema = map_schema
            .get("items")
            .expect("items schema should exist");
        assert_eq!(items_schema.get("type"), Some(&json!("object")));

        let item_props = items_schema
            .get("properties")
            .and_then(|p| p.as_object())
            .expect("items should have properties");
        assert!(item_props.contains_key("__key__"));
        assert!(item_props.contains_key("__value__"));

        // Check required fields
        let required = items_schema
            .get("required")
            .and_then(|r| r.as_array())
            .expect("items should have required");
        assert!(required.contains(&json!("__key__")));
        assert!(required.contains(&json!("__value__")));
    }

    #[test]
    fn normalize_json_response_converts_kv_arrays_to_objects() {
        let mut response = json!({
            "map": [
                { "__key__": "a", "__value__": "1" },
                { "__key__": "b", "__value__": "2" }
            ]
        });

        normalize_json_response(&mut response);

        let map = response.get("map").expect("map should exist");
        assert!(map.is_object());
        assert_eq!(map.get("a"), Some(&json!("1")));
        assert_eq!(map.get("b"), Some(&json!("2")));
    }

    #[test]
    fn normalize_json_response_handles_nested_maps() {
        let mut response = json!({
            "outer": [
                {
                    "__key__": "x",
                    "__value__": [
                        { "__key__": "inner1", "__value__": 10 },
                        { "__key__": "inner2", "__value__": 20 }
                    ]
                }
            ]
        });

        normalize_json_response(&mut response);

        let outer = response.get("outer").expect("outer should exist");
        assert!(outer.is_object());
        let x = outer.get("x").expect("x should exist");
        assert!(x.is_object());
        assert_eq!(x.get("inner1"), Some(&json!(10)));
        assert_eq!(x.get("inner2"), Some(&json!(20)));
    }

    #[test]
    fn normalize_json_response_leaves_regular_arrays_alone() {
        let mut response = json!({
            "items": [
                { "id": 1, "name": "foo" },
                { "id": 2, "name": "bar" }
            ]
        });

        let expected = response.clone();
        normalize_json_response(&mut response);

        assert_eq!(response, expected);
    }

    #[derive(JsonSchema)]
    struct Node {
        value: String,
        child: Option<Box<Node>>,
    }

    #[test]
    fn recursive_schemas_inline_refs() {
        let schema = Node::gemini_schema();
        let schema_json = schema.to_string();

        assert!(!schema_json.contains("\"$ref\""));
        assert!(!schema_json.contains("\"components\""));
    }

    // Pure string enum - should be converted to { "type": "string", "enum": [...] }
    #[derive(JsonSchema)]
    enum AccountType {
        Revenue,
        CostOfSales,
        Expense,
        Asset,
        Liability,
    }

    #[test]
    fn pure_string_enum_converts_to_string_with_enum() {
        let schema = AccountType::gemini_schema();

        // Should be type: "string" with enum values
        assert_eq!(schema.get("type"), Some(&json!("string")));

        let enum_values = schema
            .get("enum")
            .and_then(|e| e.as_array())
            .expect("enum should exist and be an array");

        // All variants should be present
        assert!(enum_values.contains(&json!("Revenue")));
        assert!(enum_values.contains(&json!("CostOfSales")));
        assert!(enum_values.contains(&json!("Expense")));
        assert!(enum_values.contains(&json!("Asset")));
        assert!(enum_values.contains(&json!("Liability")));

        // Should NOT have object properties (the old broken behavior)
        assert!(schema.get("properties").is_none());
        assert!(schema.get("oneOf").is_none());
        assert!(schema.get("anyOf").is_none());
    }

    // Mixed enum with both unit variants and struct variants
    #[derive(JsonSchema)]
    enum SeasonalityProfileId {
        Flat,
        Custom { values: Vec<f64> },
    }

    #[test]
    fn mixed_enum_preserves_anyof() {
        let schema = SeasonalityProfileId::gemini_schema();

        // Should have anyOf preserved (not flattened)
        let any_of = schema
            .get("anyOf")
            .and_then(|a| a.as_array())
            .expect("anyOf should exist and be an array");

        // Should have 2 variants
        assert_eq!(any_of.len(), 2);

        // Check that we have both string and object variants
        let has_string_variant = any_of
            .iter()
            .any(|v| v.get("type").and_then(|t| t.as_str()) == Some("string"));
        let has_object_variant = any_of
            .iter()
            .any(|v| v.get("type").and_then(|t| t.as_str()) == Some("object"));

        assert!(has_string_variant, "Should have a string variant");
        assert!(has_object_variant, "Should have an object variant");

        // Parent should NOT have type (since it could be string or object)
        assert!(schema.get("type").is_none());
    }

    // Complex object enum - should still flatten
    #[derive(JsonSchema)]
    enum Message {
        Request { id: u32, payload: String },
        Response { id: u32, result: String },
    }

    #[test]
    fn complex_object_enum_flattens() {
        let schema = Message::gemini_schema();

        // Should be flattened to an object
        assert_eq!(schema.get("type"), Some(&json!("object")));

        // Schemars uses externally-tagged format by default:
        // Each variant name becomes a property with its fields as nested object
        let properties = schema
            .get("properties")
            .and_then(|p| p.as_object())
            .expect("properties should exist");

        // Variant names should be properties
        assert!(properties.contains_key("Request"));
        assert!(properties.contains_key("Response"));

        // Each variant should have its nested properties
        let request_props = properties
            .get("Request")
            .and_then(|r| r.get("properties"))
            .and_then(|p| p.as_object())
            .expect("Request properties should exist");
        assert!(request_props.contains_key("id"));
        assert!(request_props.contains_key("payload"));

        // Should NOT have anyOf (should be flattened)
        assert!(schema.get("anyOf").is_none());
        assert!(schema.get("oneOf").is_none());
    }

    /// Test that allOf with description pattern is handled correctly.
    /// schemars often generates: { "description": "...", "allOf": [{"$ref": "..."}] }
    /// After ref inlining, the allOf contents should be merged into the parent.
    #[test]
    fn allof_with_description_merges_correctly() {
        // Simulate the pattern schemars generates after ref inlining:
        // { "description": "The processor to use", "allOf": [{ "type": "object", "properties": {...} }] }
        let mut schema = json!({
            "description": "The processor configuration",
            "allOf": [
                {
                    "type": "object",
                    "properties": {
                        "model": {
                            "type": "object",
                            "properties": {
                                "type": { "type": "string", "enum": ["mstl", "arima"] }
                            },
                            "required": ["type"]
                        }
                    },
                    "required": ["model"]
                }
            ]
        });

        clean_schema_for_gemini(&mut schema);

        // The allOf should be removed
        assert!(schema.get("allOf").is_none(), "allOf should be removed");

        // The description from the parent should be preserved
        assert_eq!(
            schema.get("description"),
            Some(&json!("The processor configuration")),
            "description should be preserved"
        );

        // The type from the allOf sub-schema should be merged into the parent
        assert_eq!(
            schema.get("type"),
            Some(&json!("object")),
            "type should be merged from allOf"
        );

        // The properties should be merged into the parent
        let properties = schema
            .get("properties")
            .and_then(|p| p.as_object())
            .expect("properties should exist after merge");
        assert!(
            properties.contains_key("model"),
            "model property should be merged from allOf"
        );

        // The required array should be merged into the parent
        let required = schema
            .get("required")
            .and_then(|r| r.as_array())
            .expect("required should exist after merge");
        assert!(
            required.contains(&json!("model")),
            "model should be in required"
        );
    }

    /// Test that nested allOf structures are handled correctly
    #[test]
    fn nested_allof_structures_merge_correctly() {
        // Parent has a description and allOf, where allOf sub-schema also has a description
        let mut schema = json!({
            "description": "Parent description",
            "allOf": [
                {
                    "type": "object",
                    "description": "Sub-schema description (should be ignored since parent has one)",
                    "properties": {
                        "name": { "type": "string" }
                    },
                    "required": ["name"]
                }
            ]
        });

        clean_schema_for_gemini(&mut schema);

        // Parent description should win (since it already existed)
        assert_eq!(
            schema.get("description"),
            Some(&json!("Parent description")),
            "parent description should be preserved"
        );

        // Type and properties should be merged
        assert_eq!(schema.get("type"), Some(&json!("object")));
        assert!(schema
            .get("properties")
            .and_then(|p| p.as_object())
            .is_some_and(|p| p.contains_key("name")));
    }

    /// Test multiple sub-schemas in allOf are all merged
    #[test]
    fn multiple_allof_subschemas_merge_correctly() {
        let mut schema = json!({
            "allOf": [
                {
                    "type": "object",
                    "properties": {
                        "id": { "type": "integer" }
                    },
                    "required": ["id"]
                },
                {
                    "properties": {
                        "name": { "type": "string" }
                    },
                    "required": ["name"]
                }
            ]
        });

        clean_schema_for_gemini(&mut schema);

        assert!(schema.get("allOf").is_none());
        assert_eq!(schema.get("type"), Some(&json!("object")));

        let properties = schema
            .get("properties")
            .and_then(|p| p.as_object())
            .expect("properties should exist");
        assert!(properties.contains_key("id"), "id should be merged");
        assert!(properties.contains_key("name"), "name should be merged");

        let required = schema
            .get("required")
            .and_then(|r| r.as_array())
            .expect("required should exist");
        assert!(required.contains(&json!("id")), "id should be required");
        assert!(required.contains(&json!("name")), "name should be required");
    }

    /// Test that array types are normalized to single types with nullable flag.
    /// Gemini API requires type: "string", not type: ["string", "null"].
    #[test]
    fn array_type_normalized_to_single_with_nullable() {
        // Standard JSON Schema nullable pattern
        let mut schema = json!({
            "type": ["integer", "null"],
            "description": "An optional count"
        });

        clean_schema_for_gemini(&mut schema);

        // Should be normalized to single type with nullable
        assert_eq!(
            schema.get("type"),
            Some(&json!("integer")),
            "type should be a single string, not an array"
        );
        assert_eq!(
            schema.get("nullable"),
            Some(&json!(true)),
            "nullable should be true"
        );
        assert_eq!(
            schema.get("description"),
            Some(&json!("An optional count")),
            "description should be preserved"
        );
    }

    /// Test array type without null is normalized to single type
    #[test]
    fn array_type_single_element_normalized() {
        let mut schema = json!({
            "type": ["string"]
        });

        clean_schema_for_gemini(&mut schema);

        assert_eq!(schema.get("type"), Some(&json!("string")));
        assert!(schema.get("nullable").is_none());
    }

    /// Test that allOf with array types are properly handled
    #[test]
    fn allof_with_array_type_normalized() {
        // Simulate allOf sub-schema having array type (from standard JSON Schema)
        let mut schema = json!({
            "description": "A nullable field",
            "allOf": [
                {
                    "type": ["integer", "null"],
                    "minimum": 0
                }
            ]
        });

        clean_schema_for_gemini(&mut schema);

        // allOf should be removed
        assert!(schema.get("allOf").is_none());

        // Type should be normalized
        assert_eq!(schema.get("type"), Some(&json!("integer")));
        assert_eq!(schema.get("nullable"), Some(&json!(true)));
        assert_eq!(schema.get("description"), Some(&json!("A nullable field")));
    }

    /// Test that internally-tagged enums collapsed to strings are recovered
    #[test]
    fn recover_internally_tagged_enum_from_string() {
        // Schema for an internally-tagged enum with "type" discriminator
        let schema = json!({
            "type": "object",
            "properties": {
                "processor": {
                    "anyOf": [
                        {
                            "type": "object",
                            "properties": {
                                "type": { "const": "mstl" }
                            },
                            "required": ["type"]
                        },
                        {
                            "type": "object",
                            "properties": {
                                "type": { "const": "arima" }
                            },
                            "required": ["type"]
                        }
                    ]
                }
            }
        });

        // Gemini collapsed the object to just the string value
        let mut value = json!({
            "processor": "mstl"
        });

        recover_internally_tagged_enums(&mut value, &schema);

        // Should be expanded back to object form
        assert_eq!(
            value.get("processor"),
            Some(&json!({"type": "mstl"})),
            "String should be recovered to object with tag field"
        );
    }

    /// Test that recovery works in nested structures (arrays)
    #[test]
    fn recover_internally_tagged_enum_in_array() {
        let schema = json!({
            "type": "object",
            "properties": {
                "items": {
                    "type": "array",
                    "items": {
                        "anyOf": [
                            {
                                "type": "object",
                                "properties": {
                                    "kind": { "const": "foo" }
                                },
                                "required": ["kind"]
                            },
                            {
                                "type": "object",
                                "properties": {
                                    "kind": { "const": "bar" }
                                },
                                "required": ["kind"]
                            }
                        ]
                    }
                }
            }
        });

        let mut value = json!({
            "items": ["foo", "bar", "foo"]
        });

        recover_internally_tagged_enums(&mut value, &schema);

        // All array items should be recovered
        let items = value.get("items").and_then(|v| v.as_array()).unwrap();
        assert_eq!(items[0], json!({"kind": "foo"}));
        assert_eq!(items[1], json!({"kind": "bar"}));
        assert_eq!(items[2], json!({"kind": "foo"}));
    }

    /// Test that recovery doesn't affect non-collapsed values
    #[test]
    fn recover_leaves_valid_objects_unchanged() {
        let schema = json!({
            "type": "object",
            "properties": {
                "processor": {
                    "anyOf": [
                        {
                            "type": "object",
                            "properties": {
                                "type": { "const": "mstl" }
                            },
                            "required": ["type"]
                        }
                    ]
                }
            }
        });

        // Already in correct object form
        let mut value = json!({
            "processor": {"type": "mstl"}
        });

        let original = value.clone();
        recover_internally_tagged_enums(&mut value, &schema);

        // Should remain unchanged
        assert_eq!(value, original);
    }

    /// Test recovery with enum (single-element array) instead of const
    #[test]
    fn recover_with_enum_schema() {
        let schema = json!({
            "type": "object",
            "properties": {
                "mode": {
                    "anyOf": [
                        {
                            "type": "object",
                            "properties": {
                                "variant": { "enum": ["alpha"] }
                            },
                            "required": ["variant"]
                        },
                        {
                            "type": "object",
                            "properties": {
                                "variant": { "enum": ["beta"] }
                            },
                            "required": ["variant"]
                        }
                    ]
                }
            }
        });

        let mut value = json!({
            "mode": "alpha"
        });

        recover_internally_tagged_enums(&mut value, &schema);

        assert_eq!(
            value.get("mode"),
            Some(&json!({"variant": "alpha"})),
            "String should be recovered using enum schema"
        );
    }

    /// Test that allOf containing oneOf (enum with description) is properly merged.
    /// This is the pattern schemars generates when a field has a description and is an enum type.
    /// Example: { "description": "The processor to use", "allOf": [{ "oneOf": [...] }] }
    #[test]
    fn allof_containing_oneof_merges_correctly() {
        // Simulate the pattern: a processor field that's an enum, wrapped in allOf with description
        let mut schema = json!({
            "description": "The processor to use",
            "allOf": [
                {
                    "oneOf": [
                        {
                            "type": "object",
                            "properties": {
                                "model": {
                                    "type": "object",
                                    "properties": {
                                        "type": { "type": "string", "enum": ["mstl", "arima"] }
                                    },
                                    "required": ["type"]
                                }
                            },
                            "required": ["model"]
                        },
                        {
                            "type": "object",
                            "properties": {
                                "custom": {
                                    "type": "object",
                                    "properties": {
                                        "name": { "type": "string" }
                                    },
                                    "required": ["name"]
                                }
                            },
                            "required": ["custom"]
                        }
                    ]
                }
            ]
        });

        clean_schema_for_gemini(&mut schema);

        // allOf should be removed
        assert!(
            schema.get("allOf").is_none(),
            "allOf should be removed after merge"
        );

        // Description should be preserved
        assert_eq!(
            schema.get("description"),
            Some(&json!("The processor to use")),
            "description should be preserved"
        );

        // The schema should NOT be empty - it should have type and properties from flattened oneOf
        // After oneOf flattening for object variants, we should have type: "object" and properties
        assert!(
            schema.get("type").is_some() || schema.get("properties").is_some(),
            "schema should have type or properties after oneOf merge, got: {}",
            serde_json::to_string_pretty(&schema).unwrap()
        );

        // Should have properties (flattened from oneOf variants)
        let properties = schema.get("properties").and_then(|p| p.as_object());
        assert!(
            properties.is_some(),
            "should have properties after flattening oneOf, got: {}",
            serde_json::to_string_pretty(&schema).unwrap()
        );

        let props = properties.unwrap();
        assert!(
            props.contains_key("model") || props.contains_key("custom"),
            "should have model or custom property, got: {:?}",
            props.keys().collect::<Vec<_>>()
        );
    }

    /// Test allOf containing a pure string enum (oneOf with const values)
    #[test]
    fn allof_containing_string_enum_merges_correctly() {
        let mut schema = json!({
            "description": "The account type",
            "allOf": [
                {
                    "oneOf": [
                        { "type": "string", "const": "Revenue" },
                        { "type": "string", "const": "Expense" },
                        { "type": "string", "const": "Asset" }
                    ]
                }
            ]
        });

        clean_schema_for_gemini(&mut schema);

        // allOf should be removed
        assert!(schema.get("allOf").is_none());

        // Description should be preserved
        assert_eq!(
            schema.get("description"),
            Some(&json!("The account type"))
        );

        // Should be converted to string enum
        assert_eq!(
            schema.get("type"),
            Some(&json!("string")),
            "should be string type"
        );

        let enum_values = schema
            .get("enum")
            .and_then(|e| e.as_array())
            .expect("should have enum values");

        assert!(enum_values.contains(&json!("Revenue")));
        assert!(enum_values.contains(&json!("Expense")));
        assert!(enum_values.contains(&json!("Asset")));
    }

    /// Test that a nested property with allOf + oneOf is properly handled
    /// This simulates the real-world case where a `processor` field inside a config struct
    /// has an enum type with a description.
    #[test]
    fn nested_property_with_allof_oneof_merges_correctly() {
        let mut schema = json!({
            "type": "object",
            "properties": {
                "name": { "type": "string" },
                "processor": {
                    "description": "The processor to use",
                    "allOf": [
                        {
                            "oneOf": [
                                {
                                    "type": "object",
                                    "properties": {
                                        "model": {
                                            "type": "object",
                                            "properties": {
                                                "type": { "type": "string", "enum": ["mstl"] }
                                            },
                                            "required": ["type"]
                                        }
                                    },
                                    "required": ["model"]
                                }
                            ]
                        }
                    ]
                }
            },
            "required": ["name", "processor"]
        });

        clean_schema_for_gemini(&mut schema);

        // Get the processor property
        let processor = schema
            .get("properties")
            .and_then(|p| p.get("processor"))
            .expect("processor property should exist");

        // allOf should be removed from processor
        assert!(
            processor.get("allOf").is_none(),
            "allOf should be removed from processor"
        );

        // Description should be preserved
        assert_eq!(
            processor.get("description"),
            Some(&json!("The processor to use")),
            "description should be preserved"
        );

        // Processor should NOT be empty - it should have the flattened structure
        assert!(
            processor.get("type").is_some() || processor.get("properties").is_some(),
            "processor should have type or properties, got: {}",
            serde_json::to_string_pretty(processor).unwrap()
        );
    }

    /// Test the complete flow: $ref inlining followed by allOf merging.
    /// This simulates how schemars generates schemas with references.
    #[test]
    fn ref_inlining_then_allof_merge_works() {
        // This is how schemars generates the schema:
        // - The processor field has { description: "...", allOf: [{ $ref: "#/$defs/ProcessorType" }] }
        // - ProcessorType is defined in $defs with a oneOf
        let mut schema = json!({
            "type": "object",
            "properties": {
                "processor": {
                    "description": "The processor to use",
                    "allOf": [
                        { "$ref": "#/$defs/ProcessorType" }
                    ]
                }
            },
            "$defs": {
                "ProcessorType": {
                    "oneOf": [
                        {
                            "type": "object",
                            "properties": {
                                "model": {
                                    "type": "object",
                                    "properties": {
                                        "type": { "type": "string", "enum": ["mstl"] }
                                    }
                                }
                            }
                        }
                    ]
                }
            }
        });

        // This is the same function called by gemini_schema()
        clean_schema_for_gemini(&mut schema);

        // $defs should be removed
        assert!(schema.get("$defs").is_none(), "$defs should be removed");

        // Get the processor property
        let processor = schema
            .get("properties")
            .and_then(|p| p.get("processor"))
            .expect("processor property should exist");

        // $ref should be inlined and allOf should be merged
        assert!(processor.get("$ref").is_none(), "$ref should be removed");
        assert!(processor.get("allOf").is_none(), "allOf should be removed");

        // Description should be preserved
        assert_eq!(
            processor.get("description"),
            Some(&json!("The processor to use"))
        );

        // The oneOf should be processed and flattened
        assert!(
            processor.get("type").is_some() || processor.get("properties").is_some(),
            "processor should have content after processing, got: {}",
            serde_json::to_string_pretty(processor).unwrap()
        );
    }

    /// Test that oneOf variants wrapped in allOf are properly cleaned before flattening.
    /// This is the key fix: schemars may wrap each variant in allOf to add descriptions,
    /// hiding the properties from the flattening logic.
    #[test]
    fn oneof_variants_with_allof_wrappers_cleaned_before_flatten() {
        // This simulates schemars output where each variant in a oneOf is wrapped in allOf
        // to attach a description to each variant.
        let mut schema = json!({
            "oneOf": [
                {
                    "description": "Model-based processor",
                    "allOf": [
                        {
                            "type": "object",
                            "properties": {
                                "model": {
                                    "type": "object",
                                    "properties": {
                                        "type": { "type": "string", "enum": ["mstl"] }
                                    },
                                    "required": ["type"]
                                }
                            },
                            "required": ["model"]
                        }
                    ]
                },
                {
                    "description": "Custom processor",
                    "allOf": [
                        {
                            "type": "object",
                            "properties": {
                                "custom": {
                                    "type": "object",
                                    "properties": {
                                        "name": { "type": "string" }
                                    },
                                    "required": ["name"]
                                }
                            },
                            "required": ["custom"]
                        }
                    ]
                }
            ]
        });

        clean_schema_for_gemini(&mut schema);

        // Should be flattened to an object with both variant properties
        assert_eq!(
            schema.get("type"),
            Some(&json!("object")),
            "should be flattened to object type"
        );

        let properties = schema
            .get("properties")
            .and_then(|p| p.as_object())
            .expect("should have properties after flattening");

        // Both variants' properties should be present
        assert!(
            properties.contains_key("model"),
            "should have 'model' property from first variant"
        );
        assert!(
            properties.contains_key("custom"),
            "should have 'custom' property from second variant"
        );

        // allOf should be completely removed
        assert!(schema.get("allOf").is_none());
        assert!(schema.get("oneOf").is_none());
    }

    /// Test deeply nested allOf inside oneOf variants
    #[test]
    fn deeply_nested_allof_in_oneof_variants() {
        let mut schema = json!({
            "type": "object",
            "properties": {
                "processor": {
                    "description": "The processor configuration",
                    "allOf": [
                        {
                            "oneOf": [
                                {
                                    "description": "MSTL variant",
                                    "allOf": [
                                        {
                                            "type": "object",
                                            "properties": {
                                                "model": {
                                                    "type": "object",
                                                    "properties": {
                                                        "type": { "type": "string", "const": "mstl" }
                                                    }
                                                }
                                            }
                                        }
                                    ]
                                }
                            ]
                        }
                    ]
                }
            }
        });

        clean_schema_for_gemini(&mut schema);

        let processor = schema
            .get("properties")
            .and_then(|p| p.get("processor"))
            .expect("processor should exist");

        // All allOf should be merged
        assert!(processor.get("allOf").is_none(), "allOf should be removed");

        // Description from outer allOf should be preserved
        assert_eq!(
            processor.get("description"),
            Some(&json!("The processor configuration"))
        );

        // Should have the flattened structure
        assert!(
            processor.get("type").is_some() || processor.get("properties").is_some(),
            "processor should have content, got: {}",
            serde_json::to_string_pretty(processor).unwrap()
        );
    }
}
